<!DOCTYPE html>
<html lang='en' ><meta charset="utf-8">
<meta name="viewport" content="width=device-width">


<title>Pytorch Tutorial | Eureka Demo</title>
<link rel="stylesheet" href="https://ihchoi12.github.io/css/eureka.min.css">
<script defer src="https://ihchoi12.github.io/js/eureka.min.js"></script>

<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="preload"
  href="https://fonts.googleapis.com/css2?family=Lora:wght@400;600;700&family=Noto+Serif+SC:wght@400;600;700&display=swap"
  as="style" onload="this.onload=null;this.rel='stylesheet'">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/styles/solarized-light.min.css"
   media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.8.6/css/academicons.min.css"
   crossorigin>
<script defer src="https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.1.0/build/highlight.min.js"
   crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.14.0/js/all.min.js"
   integrity="sha256-uNYoXefWRqv&#43;PsIF/OflNmwtKM4lStn9yrz2gVl6ymo="  crossorigin></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css"
   integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3&#43;Aro6EYUG4&#43;cU&#43;KJWu/X"  media="print"
  onload="this.media='all';this.onload=null" crossorigin>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" 
  integrity="sha384-g7c&#43;Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI&#43;sEnkvrMWph2EDg4"  crossorigin></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js"
   integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC&#43;Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa"  crossorigin></script>
<script>
  document.addEventListener("DOMContentLoaded", function () {
    renderMathInElement(document.body, {
      delimiters: [
        { left: "$$", right: "$$", display: true },
        { left: "$", right: "$", display: false },
        { left: "\\(", right: "\\)", display: false },
        { left: "\\[", right: "\\]", display: true }
      ],
    });
  });
</script>


<link rel="icon" type="image/png" sizes="32x32" href="https://ihchoi12.github.io/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_32x32_fill_box_center_3.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://ihchoi12.github.io/images/icon_hu64421c6c7700f606f0ad45d807017b09_5843_180x180_fill_box_center_3.png">

<meta name="description"
  content="To understand pytorch training codes better, I start to follow a full totorial and summarize my progress here.
Basic Concepts [source] Unlike classical programming where we input data and algorithm (rules) to get the output, we give data and output to the ML training algorithm so that it can figure out the correct output for unknown data.
Tensor  all data elements of a tensor are converted to have the same type (e.g., float) the shape of a tensor must be regular 3-dimension (difference from a simple list-of-list)  PyTorch  a library for tensor processing the underlying implementation is in CUDA language (c language, which is fast), but it provides a layer of python wrappers (which is slow, but easy to use) of CUDA API calls why it&rsquo;s great?">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
      "@type": "ListItem",
      "position": 1 ,
      "name":"Posts",
      "item":"https://ihchoi12.github.io/posts/"},{
      "@type": "ListItem",
      "position": 2 ,
      "name":"Pytorch Tutorial",
      "item":"https://ihchoi12.github.io/posts/pytorch_tutorial/"}]
}
</script>



<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://ihchoi12.github.io/posts/pytorch_tutorial/"
    },
    "headline": "Pytorch Tutorial | Eureka Demo","datePublished": "2022-06-14T15:52:29+08:00",
    "dateModified": "2022-06-14T15:52:29+08:00",
    "wordCount":  2791 ,
    "publisher": {
        "@type": "Person",
        "name": "C. Wang",
        "logo": {
            "@type": "ImageObject",
            "url": "https://ihchoi12.github.io/images/icon.png"
        }
        },
    "description": "To understand pytorch training codes better, I start to follow a full totorial and summarize my progress here.\nBasic Concepts [source] Unlike classical programming where we input data and algorithm (rules) to get the output, we give data and output to the ML training algorithm so that it can figure out the correct output for unknown data.\nTensor  all data elements of a tensor are converted to have the same type (e.g., float) the shape of a tensor must be regular 3-dimension (difference from a simple list-of-list)  PyTorch  a library for tensor processing the underlying implementation is in CUDA language (c language, which is fast), but it provides a layer of python wrappers (which is slow, but easy to use) of CUDA API calls why it\u0026rsquo;s great?"
}
</script><meta property="og:title" content="Pytorch Tutorial | Eureka Demo" />
<meta property="og:type" content="article" />


<meta property="og:image" content="https://ihchoi12.github.io/images/icon.png">


<meta property="og:url" content="https://ihchoi12.github.io/posts/pytorch_tutorial/" />




<meta property="og:description" content="To understand pytorch training codes better, I start to follow a full totorial and summarize my progress here.
Basic Concepts [source] Unlike classical programming where we input data and algorithm (rules) to get the output, we give data and output to the ML training algorithm so that it can figure out the correct output for unknown data.
Tensor  all data elements of a tensor are converted to have the same type (e.g., float) the shape of a tensor must be regular 3-dimension (difference from a simple list-of-list)  PyTorch  a library for tensor processing the underlying implementation is in CUDA language (c language, which is fast), but it provides a layer of python wrappers (which is slow, but easy to use) of CUDA API calls why it&rsquo;s great?" />




<meta property="og:locale" content="en" />




<meta property="og:site_name" content="Eureka Demo" />






<meta property="article:published_time" content="2022-06-14T15:52:29&#43;08:00" />


<meta property="article:modified_time" content="2022-06-14T15:52:29&#43;08:00" />



<meta property="article:section" content="posts" />




<body class="flex flex-col min-h-screen">
  <header class="fixed flex items-center w-full min-h-16 pl-scrollbar z-50 bg-secondary-bg shadow-sm">
    <div class="w-full max-w-screen-xl mx-auto"><script>
    let storageColorScheme = localStorage.getItem("lightDarkMode")
    if (((storageColorScheme == 'Auto' || storageColorScheme == null) && window.matchMedia("(prefers-color-scheme: dark)").matches) || storageColorScheme == "Dark") {
        document.getElementsByTagName('html')[0].classList.add('dark')
    }
</script>
<nav class="flex items-center justify-between flex-wrap p-4">
    <a href="/" class="mr-6 text-primary-text font-bold">Eureka Demo</a>
    <button id="navbar-btn" class="md:hidden flex items-center px-3 py-2" aria-label="Open Navbar">
        <i class="fas fa-bars"></i>
    </button>

    <div id="target"
        class="hidden block md:flex md:flex-grow md:justify-between md:items-center w-full md:w-auto text-primary-text z-20">
        <div class="text-sm md:flex-grow pb-4 md:pb-0 border-b md:border-b-0">
            <a href="/#about"
                class="block mt-4 md:inline-block md:mt-0  hover:text-eureka mr-4">About</a>
            <a href="/posts/"
                class="block mt-4 md:inline-block md:mt-0  text-eureka  hover:text-eureka mr-4">Posts</a>
            <a href="/docs/"
                class="block mt-4 md:inline-block md:mt-0  hover:text-eureka mr-4">Docs</a>
        </div>

        <div class="flex">
            <div class="relative pt-4 md:pt-0">
                <div class="cursor-pointer hover:text-eureka" id="lightDarkMode">
                    <i class="fas fa-adjust"></i>
                </div>
                <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-30" id="is-open">
                </div>
                <div class="absolute flex flex-col left-0 md:left-auto right-auto md:right-0 hidden bg-secondary-bg w-48 rounded py-2 border border-tertiary-bg cursor-pointer z-40"
                    id='lightDarkOptions'>
                    <span class="px-4 py-1 hover:text-eureka">Light</span>
                    <span class="px-4 py-1 hover:text-eureka">Dark</span>
                    <span class="px-4 py-1 hover:text-eureka">Auto</span>
                </div>
            </div>
        </div>
    </div>

    <div class="fixed hidden inset-0 opacity-0 h-full w-full cursor-default z-0" id="is-open-mobile">
    </div>

</nav>
<script>
    let element = document.getElementById('lightDarkMode')
    if (storageColorScheme == null || storageColorScheme == 'Auto') {
        document.addEventListener('DOMContentLoaded', () => {
            switchMode('Auto')
        })
    } else if (storageColorScheme == "Light") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'sun')
        element.firstElementChild.classList.add('fa-sun')
    } else if (storageColorScheme == "Dark") {
        element.firstElementChild.classList.remove('fa-adjust')
        element.firstElementChild.setAttribute("data-icon", 'moon')
        element.firstElementChild.classList.add('fa-moon')
    }
    
    document.addEventListener('DOMContentLoaded', () => {
        getcolorscheme();
        switchBurger();
    });
</script></div>
  </header>
  <main class="flex-grow pt-16">
      <div class="w-full max-w-screen-xl lg:px-4 xl:px-8 mx-auto">


<div class="lg:pt-12"></div>
<div
    class="col-span-2 lg:col-start-2 lg:col-span-6 bg-secondary-bg rounded px-6 py-8">
    <h1 class="font-bold text-3xl text-primary-text">Pytorch Tutorial</h1>
    <div class="mr-6 my-2">
    <span>2022-06-14</span>
</div>




    
    
    

    <div class="content">
        <p>To understand pytorch training codes better, I start to follow a full totorial and summarize my progress here.</p>
<h1 id="basic-concepts">Basic Concepts</h1>
<p align="center">
    <img src="/posts/2022-06-14-16-23-53.png" width="300" /> <br>
    <a href="https://jovian.ai/aakashns/machine-learning-intro">[source]</a> 
</p>
<p>Unlike classical programming where we input data and algorithm (rules) to get the output, we give data and output to the ML training algorithm so that it can figure out the correct output for unknown data.</p>
<h2 id="tensor">Tensor</h2>
<ul>
<li>all data elements of a tensor are converted to have the same type (e.g., float)</li>
<li>the shape of a tensor must be regular 3-dimension (difference from a simple list-of-list)</li>
</ul>
<h2 id="pytorch">PyTorch</h2>
<ul>
<li>a library for tensor processing</li>
<li>the underlying implementation is in CUDA language (c language, which is fast), but it provides a layer of python wrappers (which is slow, but easy to use) of CUDA API calls</li>
<li>why it&rsquo;s great? we can automatically compute the gradient (i.e., autograd using <code>.backward()</code>) of the output w.r.t. tensors</li>
<li>specify <code>require_grad = True</code> of a tensor to reduce unnecessary gradient calculation cost</li>
</ul>
<p>Example:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-0-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-0-12">12</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Create tensors.</span>
</span></span><span style="display:flex;"><span>x <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(<span style="color:#666">3.</span>)
</span></span><span style="display:flex;"><span>w <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(<span style="color:#666">4.</span>, requires_grad<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>b <span style="color:#666">=</span> torch<span style="color:#666">.</span>tensor(<span style="color:#666">5.</span>, requires_grad<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Arithmetic Operation</span>
</span></span><span style="display:flex;"><span>y <span style="color:#666">=</span> w <span style="color:#666">*</span> x <span style="color:#666">+</span> b
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Compute gradients using autograd</span>
</span></span><span style="display:flex;"><span>y<span style="color:#666">.</span>backward()
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Display gradients</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;dy/dx:&#39;</span>, x<span style="color:#666">.</span>grad)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;dy/dw:&#39;</span>, w<span style="color:#666">.</span>grad)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;dy/db:&#39;</span>, b<span style="color:#666">.</span>grad)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Output:</p>
<pre tabindex="0"><code>dy/dx: None
dy/dw: tensor(3.)
dy/db: tensor(1.)
</code></pre><ul>
<li>PyTorch interoperates well with <code>numpy</code>, so we can use <code>numpy</code> to easily handle our data and also take benefit of PyTorch (Autograd, tensor operations on GPU).</li>
</ul>
<h1 id="linear-regression-y--xwt--b">Linear Regression (y = xW^T + b)</h1>
<p>Linear regression is to a relationship between <strong>input variables</strong> (e.g., study time) and <strong>target variables</strong> (score). Each target variable is estimated to be a weighted sum of the input variables, offset by some constant (i.e., bias).</p>
<p>Here, <strong>learning</strong> means to figure out the weights using the training data. How? Gradient Descent: Just adjust slightly many times towards better accuracy.</p>
<p>To represent this problem mathematically, we form a matrix of the weights and vector of biases (# of target variables == # of rows).</p>
<h2 id="loss-function">Loss Function</h2>
<ul>
<li>to evaluate the model accuracy during training</li>
<li>typically use <strong>MSE</strong> (Mean Squared Error), why square? to remove negative values</li>
</ul>
<h2 id="overall-process">Overall Process</h2>
<ol>
<li>Setup Model</li>
<li>Generate Predictions</li>
<li>Calculate Loss</li>
<li>Compute Gradients w.r.t. Weights and Biases</li>
<li>Adjust Weights and Biases</li>
<li>Reset Gradients to Zero (why? gradients are accumulated throughout training)</li>
</ol>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-18">18</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-19"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-19">19</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-20"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-20">20</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-21"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-21">21</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-22"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-22">22</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-2-23"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-2-23">23</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Weights and biases</span>
</span></span><span style="display:flex;"><span>w <span style="color:#666">=</span> torch<span style="color:#666">.</span>randn(<span style="color:#666">2</span>, <span style="color:#666">3</span>, requires_grad<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>b <span style="color:#666">=</span> torch<span style="color:#666">.</span>randn(<span style="color:#666">2</span>, requires_grad<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Setup model</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">model</span>(x):
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> x <span style="color:#666">@</span> w<span style="color:#666">.</span>t() <span style="color:#666">+</span> b
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># MSE loss</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">mse</span>(t1, t2):
</span></span><span style="display:flex;"><span>    diff <span style="color:#666">=</span> t1 <span style="color:#666">-</span> t2
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> torch<span style="color:#666">.</span>sum(diff <span style="color:#666">*</span> diff) <span style="color:#666">/</span> diff<span style="color:#666">.</span>numel()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Train for 100 epochs</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">for</span> i <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#008000">range</span>(<span style="color:#666">100</span>):
</span></span><span style="display:flex;"><span>    preds <span style="color:#666">=</span> model(inputs)
</span></span><span style="display:flex;"><span>    loss <span style="color:#666">=</span> mse(preds, targets)
</span></span><span style="display:flex;"><span>    loss<span style="color:#666">.</span>backward()
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">with</span> torch<span style="color:#666">.</span>no_grad(): <span style="color:#408080;font-style:italic"># stop tracking operations while adjusting</span>
</span></span><span style="display:flex;"><span>        w <span style="color:#666">-=</span> w<span style="color:#666">.</span>grad <span style="color:#666">*</span> <span style="color:#666">1e-5</span>
</span></span><span style="display:flex;"><span>        b <span style="color:#666">-=</span> b<span style="color:#666">.</span>grad <span style="color:#666">*</span> <span style="color:#666">1e-5</span>
</span></span><span style="display:flex;"><span>        w<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_()
</span></span><span style="display:flex;"><span>        b<span style="color:#666">.</span>grad<span style="color:#666">.</span>zero_()
</span></span></code></pre></td></tr></table>
</div>
</div><p>** Note on <code>torch.no_grad()</code>: By default, PyTorch tracks all operations (during FP) on tensors with <code>required_grad=True</code>, which is called gradient context tracking by autograd engine. This tracking task has some processing and memory cost, so we deactivate it using <code>torch.no_grad()</code> when it&rsquo;s not needed.</p>
<h2 id="linear-regression-using-pytorch-built-in">Linear Regression using PyTorch Built-in</h2>
<ul>
<li>the above training process is common, so several built-ins are provided</li>
</ul>
<h3 id="packages">packages</h3>
<ul>
<li><code>from torch.utils.data import TensorDataset</code>: allow us to handle certain rows (why? to handle data into batches, see below) of data as a tuple of (input, output)</li>
</ul>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-3-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-3-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-3-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-3-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-3-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-3-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-3-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-3-4">4</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#008000;font-weight:bold">import</span> TensorDataset
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Define dataset</span>
</span></span><span style="display:flex;"><span>train_ds <span style="color:#666">=</span> TensorDataset(inputs, targets)
</span></span><span style="display:flex;"><span>train_ds[<span style="color:#666">0</span>:<span style="color:#666">3</span>]
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>from torch.utils.data import DataLoader</code>: split data into batches while shffuling</li>
</ul>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-4-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-4-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-4-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-4-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-4-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-4-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-4-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-4-4">4</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#008000;font-weight:bold">import</span> DataLoader
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Define data loader</span>
</span></span><span style="display:flex;"><span>batch_size <span style="color:#666">=</span> <span style="color:#666">11</span>
</span></span><span style="display:flex;"><span>train_dl <span style="color:#666">=</span> DataLoader(train_ds, batch_size, shuffle<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>) <span style="color:#408080;font-style:italic"># why shffle? data might be sorted by default, but we want to train overall data</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>import torch.nn as nn</code>: contains utility classes for building neural networks</li>
</ul>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-5-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-5-18">18</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch.nn</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">nn</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Define model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(<span style="color:#666">3</span>, <span style="color:#666">2</span>) <span style="color:#408080;font-style:italic"># 3 weights, 2 biases (3 inputs, 2 outputs)</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(model<span style="color:#666">.</span>weight)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(model<span style="color:#666">.</span>bias)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># model.parameters() returns a list of tensors weight and bias</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#ba2121">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">Output:
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">Parameter containing:
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">tensor([[ 0.1312, -0.4246, -0.2341],
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">        [ 0.4099,  0.4766,  0.1676]], requires_grad=True)
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">Parameter containing:
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">tensor([ 0.1603, -0.0098], requires_grad=True)
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Here, model is an object (not a function), but we can do FP in the same way</span>
</span></span><span style="display:flex;"><span>preds <span style="color:#666">=</span> model(inputs)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>import torch.nn.functional as F</code>: built-in loss function (e.g., mse_loss)</li>
</ul>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-4">4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-5">5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-6-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-6-6">6</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#666">...</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Import nn.functional</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch.nn.functional</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">F</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Define loss function</span>
</span></span><span style="display:flex;"><span>loss_fn <span style="color:#666">=</span> F<span style="color:#666">.</span>mse_loss
</span></span><span style="display:flex;"><span>loss <span style="color:#666">=</span> loss_fn(model(inputs), targets)
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>torch.optim.SGD</code>: optimize parameters using gradients instead of manually updating them (meaning of stochastic: batches are selected with random shuffling instead of the entire data)</li>
</ul>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-7-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-7-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-7-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-7-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-7-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-7-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-7-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-7-4">4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-7-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-7-5">5</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Define optimizer</span>
</span></span><span style="display:flex;"><span>opt <span style="color:#666">=</span> torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD(model<span style="color:#666">.</span>parameters(), lr<span style="color:#666">=</span><span style="color:#666">1e-5</span>)
</span></span><span style="display:flex;"><span><span style="color:#ba2121">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">tell the optimizer: &#34;matrices model.parameters() need to be updated 
</span></span></span><span style="display:flex;"><span><span style="color:#ba2121">&#34;&#34;&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<p>Using all these built-ins, training model can be implemented again as follows:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-18">18</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-19"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-19">19</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-20"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-20">20</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-21"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-21">21</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-22"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-22">22</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-23"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-23">23</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-24"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-24">24</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-25"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-25">25</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-26"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-26">26</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-27"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-27">27</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-28"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-28">28</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-29"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-29">29</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-30"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-30">30</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-8-31"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-8-31">31</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#666">...</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Utility function to train the model</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">fit</span>(num_epochs, model, loss_fn, opt, train_dl):
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#408080;font-style:italic"># Repeat for given number of epochs</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#008000">range</span>(num_epochs):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Train with batches of data</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">for</span> xb,yb <span style="color:#a2f;font-weight:bold">in</span> train_dl: 
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># train_dl is a list of tuples of tensors (input, output), while each tensor has a batch of tensors</span>
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># 1. Generate predictions</span>
</span></span><span style="display:flex;"><span>            pred <span style="color:#666">=</span> model(xb)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># 2. Calculate loss</span>
</span></span><span style="display:flex;"><span>            loss <span style="color:#666">=</span> loss_fn(pred, yb)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># 3. Compute gradients</span>
</span></span><span style="display:flex;"><span>            loss<span style="color:#666">.</span>backward()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># 4. Update parameters using gradients</span>
</span></span><span style="display:flex;"><span>            opt<span style="color:#666">.</span>step()
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># 5. Reset the gradients to zero</span>
</span></span><span style="display:flex;"><span>            opt<span style="color:#666">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Print the progress</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">if</span> (epoch<span style="color:#666">+</span><span style="color:#666">1</span>) <span style="color:#666">%</span> <span style="color:#666">10</span> <span style="color:#666">==</span> <span style="color:#666">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;Epoch [</span><span style="color:#b68;font-weight:bold">{}</span><span style="color:#ba2121">/</span><span style="color:#b68;font-weight:bold">{}</span><span style="color:#ba2121">], Loss: </span><span style="color:#b68;font-weight:bold">{:.4f}</span><span style="color:#ba2121">&#39;</span><span style="color:#666">.</span>format(epoch<span style="color:#666">+</span><span style="color:#666">1</span>, num_epochs, loss<span style="color:#666">.</span>item())) <span style="color:#408080;font-style:italic"># loss is tensor of a single value, so loss.item retrieves the value</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>fit(<span style="color:#666">100</span>, model, loss_fn, opt, train_dl) <span style="color:#408080;font-style:italic"># train for 100 epochs</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="note-why-stochastic-batches-with-random-shuffling-instead-of-the-enrtire-dataset">Note: why stochastic (batches with random shuffling) instead of the enrtire dataset?</h3>
<ul>
<li>memory: no need to fit the entire data at once</li>
<li>accuracy: gives more chances for convergence</li>
<li>total amount of computation should be the same eventually</li>
<li>performance will be lower though (due to less parallelization).</li>
</ul>
<p align="center">
    <img src="/posts/sgd.png" width="600" /> <br>
    <a href="https://arxiv.org/pdf/1802.09941.pdf">[source]</a> 
</p>
<h1 id="logistic-regression-for-image-classification">Logistic Regression for Image Classification</h1>
<p>The problem setup is different from the linear regression as follows:</p>
<ul>
<li>Input: a number of variables -&gt; a single image</li>
<li>Output: a number of variables -&gt; a single label</li>
<li>Example: a single MNIST data consist of one image and it&rsquo;s label</li>
</ul>
<p>However, PyTorch is a library to handle tensors, so we need to convert the images to tensors. It can be doen using <code>torchvision.transform</code>:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-9-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-9-10">10</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torchvision</span> <span style="color:#408080;font-style:italic"># a package of utilities for working with image data</span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torchvision.transforms</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">transforms</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># MNIST dataset, 1 data = (image, label)</span>
</span></span><span style="display:flex;"><span>dataset <span style="color:#666">=</span> MNIST(root<span style="color:#666">=</span><span style="color:#ba2121">&#39;data/&#39;</span>, 
</span></span><span style="display:flex;"><span>                train<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>,
</span></span><span style="display:flex;"><span>                transform<span style="color:#666">=</span>transforms<span style="color:#666">.</span>ToTensor())
</span></span><span style="display:flex;"><span>img_tensor, label <span style="color:#666">=</span> dataset[<span style="color:#666">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#008000">len</span>(dataset), img_tensor<span style="color:#666">.</span>shape, label) 
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># 60000, torch.Size([1, 28, 28]), 5 </span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then, we split the training dataset into <strong>training set</strong> and <strong>validation set</strong>, so that we can use different datasets for validation and training (note: MNIST has a separate dataset for test with 10000 images). What is the difference between validation and test? Validation is to evaluate the model during training and adjust hyperparameters (learning rate, etc.). Test is to measure the final accuracy and compare to other models.</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-10-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-10-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-10-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-10-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-10-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-10-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-10-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-10-4">4</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#008000;font-weight:bold">import</span> random_split
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_ds, val_ds <span style="color:#666">=</span> random_split(dataset, [<span style="color:#666">50000</span>, <span style="color:#666">10000</span>])
</span></span><span style="display:flex;"><span><span style="color:#008000">len</span>(train_ds), <span style="color:#008000">len</span>(val_ds) <span style="color:#408080;font-style:italic"># 50000, 10000</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then, we batch the data:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-4">4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-5">5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-11-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-11-6">6</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">from</span> <span style="color:#00f;font-weight:bold">torch.utils.data</span> <span style="color:#008000;font-weight:bold">import</span> DataLoader
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>batch_size <span style="color:#666">=</span> <span style="color:#666">128</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_loader <span style="color:#666">=</span> DataLoader(train_ds, batch_size, shuffle<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>) <span style="color:#408080;font-style:italic"># invoke shuffle for each epoch to randomize (i.e., generalize), which helps faster convergence   </span>
</span></span><span style="display:flex;"><span>val_loader <span style="color:#666">=</span> DataLoader(val_ds, batch_size) <span style="color:#408080;font-style:italic"># no need to be shuffled (it&#39;s not for training)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>We have prepared the dataset for training. Then, how can we set the model? Interestingly, the training model is conceptually the same as linear regression (y = xW^T + b). Each pixel (of 28*28) is weighted individually, to predict the probability of the image to be each label.</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-4">4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-5">5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-6">6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-7">7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-8">8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-12-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-12-9">9</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">import</span> <span style="color:#00f;font-weight:bold">torch.nn</span> <span style="color:#008000;font-weight:bold">as</span> <span style="color:#00f;font-weight:bold">nn</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>input_size <span style="color:#666">=</span> <span style="color:#666">28</span><span style="color:#666">*</span><span style="color:#666">28</span>
</span></span><span style="display:flex;"><span>num_classes <span style="color:#666">=</span> <span style="color:#666">10</span> <span style="color:#408080;font-style:italic"># number of outputs (labels)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Logistic regression model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(input_size, num_classes)
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(model<span style="color:#666">.</span>weight<span style="color:#666">.</span>shape) <span style="color:#408080;font-style:italic"># torch.Size([10, 784])</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(model<span style="color:#666">.</span>bias<span style="color:#666">.</span>shape) <span style="color:#408080;font-style:italic"># torch.Size([10])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>However, one issue is that the input (image) and weight shape mismatch (1,28,28 vs 784). So, we <code>reshape</code> the input before we do FP. We can add this additional functionality by extending the default <code>nn.Module</code> class from PyTorch:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-13-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-13-12">12</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">class</span> <span style="color:#00f;font-weight:bold">MnistModel</span>(nn<span style="color:#666">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#008000">super</span>()<span style="color:#666">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>linear <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(input_size, num_classes)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">forward</span>(self, xb):
</span></span><span style="display:flex;"><span>        xb <span style="color:#666">=</span> xb<span style="color:#666">.</span>reshape(<span style="color:#666">-</span><span style="color:#666">1</span>, <span style="color:#666">784</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># by giving -1 for the first dimension, PyTorch automatically calculate it depending on the input, so we can use it with any batch size of xb </span>
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self<span style="color:#666">.</span>linear(xb)
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>model <span style="color:#666">=</span> MnistModel()
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, we can use the <code>model</code> for FP:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-14-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-14-10">10</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">for</span> images, labels <span style="color:#a2f;font-weight:bold">in</span> train_loader:
</span></span><span style="display:flex;"><span>    <span style="color:#008000">print</span>(images<span style="color:#666">.</span>shape)
</span></span><span style="display:flex;"><span>    outputs <span style="color:#666">=</span> model(images) <span style="color:#408080;font-style:italic"># the base class nn.Module calls the forward() method by default</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;outputs.shape : &#39;</span>, outputs<span style="color:#666">.</span>shape) 
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># outputs.shape :  torch.Size([128, 10])</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#39;Sample outputs :</span><span style="color:#b62;font-weight:bold">\n</span><span style="color:#ba2121">&#39;</span>, outputs[:<span style="color:#666">2</span>]<span style="color:#666">.</span>data)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Sample outputs :</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># tensor([[ 0.0245,  0.0691, -0.1861,  0.1229, -0.1947, -0.1299,  0.1847, -0.2836, 0.2063, -0.1164], [-0.2538,  0.0495, -0.0900,  0.0783,  0.0670, -0.2608, -0.1726, -0.0452, 0.1272,  0.0451]])</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Then, we want to convert the output into probability of each label. For this, we use Softmax function provided by <code>import torch.nn.functional as F</code>:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-15-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-15-10">10</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Apply softmax for each output row</span>
</span></span><span style="display:flex;"><span>probs <span style="color:#666">=</span> F<span style="color:#666">.</span>softmax(outputs, dim<span style="color:#666">=</span><span style="color:#666">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Look at sample probabilities</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Sample probabilities:</span><span style="color:#b62;font-weight:bold">\n</span><span style="color:#ba2121">&#34;</span>, probs[:<span style="color:#666">2</span>]<span style="color:#666">.</span>data)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Sample probabilities:</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># tensor([[0.1042, 0.1090, 0.0844, 0.1150, 0.0837, 0.0893, 0.1223, 0.0766, 0.1250, 0.0905], [0.0805, 0.1090, 0.0948, 0.1122, 0.1109, 0.0799, 0.0873, 0.0991, 0.1178, 0.1085]])</span>
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Add up the probabilities of an output row</span>
</span></span><span style="display:flex;"><span><span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Sum: &#34;</span>, torch<span style="color:#666">.</span>sum(probs[<span style="color:#666">0</span>])<span style="color:#666">.</span>item())
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Sum:  0.9999999403953552</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Now, we can calculate the accuracy of our model as follows:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-16-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-16-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-16-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-16-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-16-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-16-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-16-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-16-4">4</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">accuracy</span>(outputs, labels):
</span></span><span style="display:flex;"><span>    _, preds <span style="color:#666">=</span> torch<span style="color:#666">.</span>max(outputs, dim<span style="color:#666">=</span><span style="color:#666">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#408080;font-style:italic"># torch.max(dim=1) returns each row&#39;s largest element and the corresponding index.</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> torch<span style="color:#666">.</span>tensor(torch<span style="color:#666">.</span>sum(preds <span style="color:#666">==</span> labels)<span style="color:#666">.</span>item() <span style="color:#666">/</span> <span style="color:#008000">len</span>(preds))
</span></span></code></pre></td></tr></table>
</div>
</div><p>Although this accuracy is intuitive to human, we cannot use it for loss function in gradient descent algorithm, because:</p>
<ol>
<li><code>torch.max()</code> and <code>==</code> are both non-continuous and non-differentiable operations</li>
<li>by taking only the final label with the maximum probability, it does NOT have enough insight about how to update the weights of each label (i.e., each column in W)</li>
</ol>
<p>So, for the loss function in classification problems, we commonly use <strong>cross entropy</strong> instead. This cross entropy is also provided by <code>torch.nn.functional</code>, and it internally includes the softmax operation as well (we need to pass the raw output). For a batch of data, the cross entropy averages out over all data samples.</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-17-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-17-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-17-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-17-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-17-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-17-3">3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-17-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-17-4">4</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>loss_fn <span style="color:#666">=</span> F<span style="color:#666">.</span>cross_entropy
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Loss for current batch of data</span>
</span></span><span style="display:flex;"><span>loss <span style="color:#666">=</span> loss_fn(outputs, labels)
</span></span><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Interpretation: our model predicted the correct label with probability e^(-loss) in avg</span>
</span></span></code></pre></td></tr></table>
</div>
</div><hr>
<p>Using the above logics, the overall training process is implemented as follows:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-18">18</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-19"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-19">19</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-20"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-20">20</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-21"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-21">21</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-22"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-22">22</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-23"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-23">23</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-24"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-24">24</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-25"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-25">25</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-26"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-26">26</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-27"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-27">27</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-28"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-28">28</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-29"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-29">29</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-30"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-30">30</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-31"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-31">31</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-32"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-32">32</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-33"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-33">33</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-34"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-34">34</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-35"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-35">35</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-36"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-36">36</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-37"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-37">37</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-38"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-38">38</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-39"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-39">39</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-40"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-40">40</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-41"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-41">41</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-42"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-42">42</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-43"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-43">43</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-44"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-44">44</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-45"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-45">45</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-46"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-46">46</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-47"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-47">47</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-48"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-48">48</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-49"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-49">49</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-50"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-50">50</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-51"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-51">51</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-52"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-52">52</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-53"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-53">53</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-54"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-54">54</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-55"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-55">55</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-56"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-56">56</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-57"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-57">57</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-58"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-58">58</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-18-59"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-18-59">59</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">evaluate</span>(model, val_loader):
</span></span><span style="display:flex;"><span>    outputs <span style="color:#666">=</span> [model<span style="color:#666">.</span>validation_step(batch) <span style="color:#008000;font-weight:bold">for</span> batch <span style="color:#a2f;font-weight:bold">in</span> val_loader]
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> model<span style="color:#666">.</span>validation_epoch_end(outputs)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">class</span> <span style="color:#00f;font-weight:bold">MnistModel</span>(nn<span style="color:#666">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __init__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#008000">super</span>()<span style="color:#666">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>linear <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(input_size, num_classes)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">forward</span>(self, xb):
</span></span><span style="display:flex;"><span>        xb <span style="color:#666">=</span> xb<span style="color:#666">.</span>reshape(<span style="color:#666">-</span><span style="color:#666">1</span>, <span style="color:#666">784</span>)
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self<span style="color:#666">.</span>linear(xb)
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">training_step</span>(self, batch):
</span></span><span style="display:flex;"><span>        images, labels <span style="color:#666">=</span> batch 
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self(images)                  <span style="color:#408080;font-style:italic"># Generate predictions</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#666">=</span> F<span style="color:#666">.</span>cross_entropy(out, labels) <span style="color:#408080;font-style:italic"># Calculate loss</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> loss
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">validation_step</span>(self, batch):
</span></span><span style="display:flex;"><span>        images, labels <span style="color:#666">=</span> batch 
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self(images)                    <span style="color:#408080;font-style:italic"># Generate predictions</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#666">=</span> F<span style="color:#666">.</span>cross_entropy(out, labels)   <span style="color:#408080;font-style:italic"># Calculate loss</span>
</span></span><span style="display:flex;"><span>        acc <span style="color:#666">=</span> accuracy(out, labels)           <span style="color:#408080;font-style:italic"># Calculate accuracy</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> {<span style="color:#ba2121">&#39;val_loss&#39;</span>: loss, <span style="color:#ba2121">&#39;val_acc&#39;</span>: acc}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">validation_epoch_end</span>(self, outputs):
</span></span><span style="display:flex;"><span>        batch_losses <span style="color:#666">=</span> [x[<span style="color:#ba2121">&#39;val_loss&#39;</span>] <span style="color:#008000;font-weight:bold">for</span> x <span style="color:#a2f;font-weight:bold">in</span> outputs]
</span></span><span style="display:flex;"><span>        epoch_loss <span style="color:#666">=</span> torch<span style="color:#666">.</span>stack(batch_losses)<span style="color:#666">.</span>mean()   <span style="color:#408080;font-style:italic"># Combine losses</span>
</span></span><span style="display:flex;"><span>        batch_accs <span style="color:#666">=</span> [x[<span style="color:#ba2121">&#39;val_acc&#39;</span>] <span style="color:#008000;font-weight:bold">for</span> x <span style="color:#a2f;font-weight:bold">in</span> outputs]
</span></span><span style="display:flex;"><span>        epoch_acc <span style="color:#666">=</span> torch<span style="color:#666">.</span>stack(batch_accs)<span style="color:#666">.</span>mean()      <span style="color:#408080;font-style:italic"># Combine accuracies</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> {<span style="color:#ba2121">&#39;val_loss&#39;</span>: epoch_loss<span style="color:#666">.</span>item(), <span style="color:#ba2121">&#39;val_acc&#39;</span>: epoch_acc<span style="color:#666">.</span>item()}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">epoch_end</span>(self, epoch, result):
</span></span><span style="display:flex;"><span>        <span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Epoch [</span><span style="color:#b68;font-weight:bold">{}</span><span style="color:#ba2121">], val_loss: </span><span style="color:#b68;font-weight:bold">{:.4f}</span><span style="color:#ba2121">, val_acc: </span><span style="color:#b68;font-weight:bold">{:.4f}</span><span style="color:#ba2121">&#34;</span><span style="color:#666">.</span>format(epoch, result[<span style="color:#ba2121">&#39;val_loss&#39;</span>], result[<span style="color:#ba2121">&#39;val_acc&#39;</span>]))
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>model <span style="color:#666">=</span> MnistModel()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">fit</span>(epochs, lr, model, train_loader, val_loader, opt_func<span style="color:#666">=</span>torch<span style="color:#666">.</span>optim<span style="color:#666">.</span>SGD):
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#666">=</span> opt_func(model<span style="color:#666">.</span>parameters(), lr)
</span></span><span style="display:flex;"><span>    history <span style="color:#666">=</span> [] <span style="color:#408080;font-style:italic"># for recording epoch-wise results</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">for</span> epoch <span style="color:#a2f;font-weight:bold">in</span> <span style="color:#008000">range</span>(epochs):
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Training Phase </span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">for</span> batch <span style="color:#a2f;font-weight:bold">in</span> train_loader:
</span></span><span style="display:flex;"><span>            loss <span style="color:#666">=</span> model<span style="color:#666">.</span>training_step(batch)
</span></span><span style="display:flex;"><span>            loss<span style="color:#666">.</span>backward()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#666">.</span>step()
</span></span><span style="display:flex;"><span>            optimizer<span style="color:#666">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Validation phase</span>
</span></span><span style="display:flex;"><span>        result <span style="color:#666">=</span> evaluate(model, val_loader)
</span></span><span style="display:flex;"><span>        model<span style="color:#666">.</span>epoch_end(epoch, result)
</span></span><span style="display:flex;"><span>        history<span style="color:#666">.</span>append(result)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> history
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="limitations-and-improvement">Limitations and Improvement</h2>
<p>The above training algorithm works pretty well, but the accuracy improvement is saturated after about 80%. There are two potential reasons:</p>
<ol>
<li>the learning rate is too high, so the model is &ldquo;bouncing&rdquo; around the optimal state</li>
<li>the linear model is not &ldquo;powerful&rdquo; enough</li>
</ol>
<p>To make the model more powerful, we can add one more layer along with a hidden layer (ReLU) to add non-linearity:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-18">18</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-19"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-19">19</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-20"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-20">20</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-21"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-21">21</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-22"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-22">22</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-23"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-23">23</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-24"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-24">24</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-25"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-25">25</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-26"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-26">26</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-27"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-27">27</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-28"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-28">28</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-29"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-29">29</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-30"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-30">30</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-31"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-31">31</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-32"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-32">32</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-33"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-33">33</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-34"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-34">34</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-35"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-35">35</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-36"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-36">36</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-37"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-37">37</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-38"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-38">38</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-39"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-39">39</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-40"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-40">40</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-41"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-41">41</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-19-42"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-19-42">42</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">class</span> <span style="color:#00f;font-weight:bold">MnistModel</span>(nn<span style="color:#666">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#ba2121">&#34;&#34;&#34;Feedfoward neural network with 1 hidden layer&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __init__(self, in_size, hidden_size, out_size):
</span></span><span style="display:flex;"><span>        <span style="color:#008000">super</span>()<span style="color:#666">.</span>__init__()
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># hidden layer</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>linear1 <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(in_size, hidden_size)
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># output layer</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>linear2 <span style="color:#666">=</span> nn<span style="color:#666">.</span>Linear(hidden_size, out_size)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">forward</span>(self, xb):
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Flatten the image tensors</span>
</span></span><span style="display:flex;"><span>        xb <span style="color:#666">=</span> xb<span style="color:#666">.</span>view(xb<span style="color:#666">.</span>size(<span style="color:#666">0</span>), <span style="color:#666">-</span><span style="color:#666">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Get intermediate outputs using hidden layer</span>
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self<span style="color:#666">.</span>linear1(xb)
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Apply activation function</span>
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> F<span style="color:#666">.</span>relu(out)
</span></span><span style="display:flex;"><span>        <span style="color:#408080;font-style:italic"># Get predictions using output layer</span>
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self<span style="color:#666">.</span>linear2(out)
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> out
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">training_step</span>(self, batch):
</span></span><span style="display:flex;"><span>        images, labels <span style="color:#666">=</span> batch 
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self(images)                  <span style="color:#408080;font-style:italic"># Generate predictions</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#666">=</span> F<span style="color:#666">.</span>cross_entropy(out, labels) <span style="color:#408080;font-style:italic"># Calculate loss</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> loss
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">validation_step</span>(self, batch):
</span></span><span style="display:flex;"><span>        images, labels <span style="color:#666">=</span> batch 
</span></span><span style="display:flex;"><span>        out <span style="color:#666">=</span> self(images)                    <span style="color:#408080;font-style:italic"># Generate predictions</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#666">=</span> F<span style="color:#666">.</span>cross_entropy(out, labels)   <span style="color:#408080;font-style:italic"># Calculate loss</span>
</span></span><span style="display:flex;"><span>        acc <span style="color:#666">=</span> accuracy(out, labels)           <span style="color:#408080;font-style:italic"># Calculate accuracy</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> {<span style="color:#ba2121">&#39;val_loss&#39;</span>: loss, <span style="color:#ba2121">&#39;val_acc&#39;</span>: acc}
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">validation_epoch_end</span>(self, outputs):
</span></span><span style="display:flex;"><span>        batch_losses <span style="color:#666">=</span> [x[<span style="color:#ba2121">&#39;val_loss&#39;</span>] <span style="color:#008000;font-weight:bold">for</span> x <span style="color:#a2f;font-weight:bold">in</span> outputs]
</span></span><span style="display:flex;"><span>        epoch_loss <span style="color:#666">=</span> torch<span style="color:#666">.</span>stack(batch_losses)<span style="color:#666">.</span>mean()   <span style="color:#408080;font-style:italic"># Combine losses</span>
</span></span><span style="display:flex;"><span>        batch_accs <span style="color:#666">=</span> [x[<span style="color:#ba2121">&#39;val_acc&#39;</span>] <span style="color:#008000;font-weight:bold">for</span> x <span style="color:#a2f;font-weight:bold">in</span> outputs]
</span></span><span style="display:flex;"><span>        epoch_acc <span style="color:#666">=</span> torch<span style="color:#666">.</span>stack(batch_accs)<span style="color:#666">.</span>mean()      <span style="color:#408080;font-style:italic"># Combine accuracies</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> {<span style="color:#ba2121">&#39;val_loss&#39;</span>: epoch_loss<span style="color:#666">.</span>item(), <span style="color:#ba2121">&#39;val_acc&#39;</span>: epoch_acc<span style="color:#666">.</span>item()}
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">epoch_end</span>(self, epoch, result):
</span></span><span style="display:flex;"><span>        <span style="color:#008000">print</span>(<span style="color:#ba2121">&#34;Epoch [</span><span style="color:#b68;font-weight:bold">{}</span><span style="color:#ba2121">], val_loss: </span><span style="color:#b68;font-weight:bold">{:.4f}</span><span style="color:#ba2121">, val_acc: </span><span style="color:#b68;font-weight:bold">{:.4f}</span><span style="color:#ba2121">&#34;</span><span style="color:#666">.</span>format(epoch, result[<span style="color:#ba2121">&#39;val_loss&#39;</span>], result[<span style="color:#ba2121">&#39;val_acc&#39;</span>]))
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="using-a-gpu">Using a GPU</h1>
<p>As the dataset and model are getting bigger, we use GPUs to train our model in a reasonable amount of time. First, let&rsquo;s see how to move our data to GPU. We define a <code>DeviceDataLoader</code> which wraps the existing <code>DataLoader</code> and move the batches one by one to GPU.</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-1"> 1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-2"> 2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-3"> 3</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-4"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-4"> 4</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-5"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-5"> 5</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-6"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-6"> 6</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-7"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-7"> 7</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-8"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-8"> 8</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-9"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-9"> 9</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-10"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-10">10</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-11"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-11">11</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-12"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-12">12</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-13"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-13">13</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-14"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-14">14</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-15"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-15">15</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-16"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-16">16</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-17"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-17">17</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-18"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-18">18</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-19"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-19">19</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-20"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-20">20</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-21"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-21">21</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-22"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-22">22</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-23"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-23">23</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-24"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-24">24</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-25"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-25">25</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-26"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-26">26</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-27"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-27">27</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-28"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-28">28</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-20-29"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-20-29">29</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">get_default_device</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#ba2121">&#34;&#34;&#34;Pick GPU if available, else CPU&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">if</span> torch<span style="color:#666">.</span>cuda<span style="color:#666">.</span>is_available():
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> torch<span style="color:#666">.</span>device(<span style="color:#ba2121">&#39;cuda&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> torch<span style="color:#666">.</span>device(<span style="color:#ba2121">&#39;cpu&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">def</span> <span style="color:#00f">to_device</span>(data, device):
</span></span><span style="display:flex;"><span>    <span style="color:#ba2121">&#34;&#34;&#34;Move tensor(s) to chosen device&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">if</span> <span style="color:#008000">isinstance</span>(data, (<span style="color:#008000">list</span>,<span style="color:#008000">tuple</span>)):
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> [to_device(x, device) <span style="color:#008000;font-weight:bold">for</span> x <span style="color:#a2f;font-weight:bold">in</span> data]
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">return</span> data<span style="color:#666">.</span>to(device, non_blocking<span style="color:#666">=</span><span style="color:#008000;font-weight:bold">True</span>)
</span></span><span style="display:flex;"><span><span style="color:#008000;font-weight:bold">class</span> <span style="color:#00f;font-weight:bold">DeviceDataLoader</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#ba2121">&#34;&#34;&#34;Wrap a dataloader to move data to a device&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __init__(self, dl, device):
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>dl <span style="color:#666">=</span> dl
</span></span><span style="display:flex;"><span>        self<span style="color:#666">.</span>device <span style="color:#666">=</span> device
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __iter__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#ba2121">&#34;&#34;&#34;Yield a batch of data after moving it to device&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">for</span> b <span style="color:#a2f;font-weight:bold">in</span> self<span style="color:#666">.</span>dl: 
</span></span><span style="display:flex;"><span>            <span style="color:#008000;font-weight:bold">yield</span> to_device(b, self<span style="color:#666">.</span>device)
</span></span><span style="display:flex;"><span>            <span style="color:#408080;font-style:italic"># Keyword &#39;yield&#39;? It generates a value to be returned when the object is accessed. Here, one batch of data will be moved to GPU and returned every time this dala loader is accessed in for loop.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#008000;font-weight:bold">def</span> __len__(self):
</span></span><span style="display:flex;"><span>        <span style="color:#ba2121">&#34;&#34;&#34;Number of batches&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#008000;font-weight:bold">return</span> <span style="color:#008000">len</span>(self<span style="color:#666">.</span>dl)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>device <span style="color:#666">=</span> get_default_device()
</span></span><span style="display:flex;"><span>train_loader <span style="color:#666">=</span> DeviceDataLoader(train_loader, device)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Note that we are moving only the data batch to be trained at the time to GPU using <code>yield</code> keyworkd. It&rsquo;s to reduce waste of GPU memories. Also, removing the trained data from GPU is automatically done by garbage collection.</p>
<p>Then, we move the model to the GPU:</p>
<div class="highlight"><div style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-21-1"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-21-1">1</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-21-2"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-21-2">2</a>
</span><span style="white-space:pre;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f" id="hl-21-3"><a style="outline: none; text-decoration:none; color:inherit" href="#hl-21-3">3</a>
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style=";-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#408080;font-style:italic"># Model (on GPU)</span>
</span></span><span style="display:flex;"><span>model <span style="color:#666">=</span> MnistModel(input_size, hidden_size<span style="color:#666">=</span>hidden_size, out_size<span style="color:#666">=</span>num_classes)
</span></span><span style="display:flex;"><span>to_device(model, device)
</span></span></code></pre></td></tr></table>
</div>
</div><h1 id="convolutional-neural-network">Convolutional Neural Network</h1>
<p>To solve more complex problems using ML, we need to use more powerful models. CNN (<code>nn.Conv2d</code>) is one example of that.</p>
<h2 id="kernel-and-convolution">Kernel and Convolution</h2>
<ul>
<li>Kernel: a matrix of weights</li>
<li>Convolution: an operation of sliding the kernel over the 2D input data, performing an elementwise multiplication, and then summing up the results into a single output pixel</li>
</ul>
<p>For multi-channel images, a different kernel is applied to each channels, and the outputs are added together pixel-wise.</p>
<h2 id="advantages">Advantages</h2>
<ul>
<li>Fewer parameters compared to FC layer where we have weight for every input element</li>
<li>Sparsity of connections since each output element depends on only a small part of input elements, which makes FP and BP more efficient</li>
<li>Parameter sharing by using the kernel trained in one part of input to detect a similar pattern in another part as well</li>
</ul>
<h2 id="max-pooling">Max-pooling</h2>
<p>From each convolutional layer, we can use max-pooling layers to progressively decrease height &amp; width of the output tensors</p>
<p align="center">
    <img src="/posts/max-pooling.png" width="300" /> <br>
    <a href="https://jovian.ai/aakashns/05-cifar10-cnn">[source]</a> 
</p>
<h1 id="reference">Reference</h1>
<ul>
<li><a href="https://www.youtube.com/watch?v=GIsg-ZUy0MY">https://www.youtube.com/watch?v=GIsg-ZUy0MY</a></li>
</ul>

    </div>
    
    
    
    
    
    
    
<div class="flex flex-col md:flex-row md:justify-between -mx-2 mt-4 px-2 pt-4 border-t">
    <div>
        
        <span class="block font-bold">Previous</span>
        <a href="https://ihchoi12.github.io/posts/aws_sagemaker/" class="block">AWS SageMaker</a>
        
    </div>
    <div class="md:text-right mt-4 md:mt-0">
        
        <span class="block font-bold">Next</span>
        <a href="https://ihchoi12.github.io/posts/math-support/" class="block">Math Support</a>
        
    </div>
</div>

    
</div>




</div>
<script>
    document.addEventListener('DOMContentLoaded', ()=>{
        hljs.initHighlightingOnLoad();
    })
</script>

      </div>
    
  </main>
  <footer class="pl-scrollbar">
    <div class="w-full max-w-screen-xl mx-auto"><div class="text-center p-6 pin-b">
    <p class="text-sm text-tertiary-text">&copy; 2021 <a href="https://www.wangchucheng.com/">C. Wang</a> and <a href="https://www.ruiqima.com/">R. Ma</a> &middot;  Powered by the <a href="https://github.com/wangchucheng/hugo-eureka" class="hover:text-eureka">Eureka</a> theme for <a href="https://gohugo.io" class="hover:text-eureka">Hugo</a></p>
</div></div>
  </footer>
</body>

</html>